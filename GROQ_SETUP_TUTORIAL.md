# üöÄ H∆∞·ªõng d·∫´n Setup Groq cho Landing Hub - Chi ti·∫øt t·ª´ng b∆∞·ªõc

## ‚ú® T·∫°i sao ch·ªçn Groq?

### So s√°nh v·ªõi c√°c providers kh√°c:

| Ti√™u ch√≠ | Groq | OpenAI | Gemini | Ollama |
|----------|------|--------|--------|--------|
| **Gi√°** | FREE ‚úÖ | $0.15-0.60/1M | FREE ‚úÖ | FREE ‚úÖ |
| **T·ªëc ƒë·ªô** | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö° |
| **Ch·∫•t l∆∞·ª£ng** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Rate Limit** | 30 req/min | Unlimited (paid) | 15 req/min | Unlimited (local) |
| **Setup** | 5 ph√∫t | 5 ph√∫t | 5 ph√∫t | 30 ph√∫t |
| **Ti·∫øng Vi·ªát** | T·ªët ‚úÖ | R·∫•t t·ªët ‚úÖ | T·ªët ‚úÖ | Kh√° |

**K·∫øt lu·∫≠n**: Groq = **Mi·ªÖn ph√≠ + Nhanh nh·∫•t + Ch·∫•t l∆∞·ª£ng t·ªët** ‚Üí Perfect cho chatbot!

---

## üìã B∆∞·ªõc 1: ƒêƒÉng k√Ω Groq

### 1.1. Truy c·∫≠p Groq Console

```
https://console.groq.com/
```

### 1.2. ƒêƒÉng k√Ω t√†i kho·∫£n

- Click **"Sign Up"** ho·∫∑c **"Get Started"**
- Ch·ªçn ph∆∞∆°ng th·ª©c ƒëƒÉng k√Ω:
  - **Email + Password** (recommend)
  - **Google Account**
  - **GitHub Account**

![Groq Sign Up](https://i.imgur.com/example-signup.png)

### 1.3. X√°c th·ª±c email

- Check email inbox
- Click link x√°c th·ª±c
- Login v√†o Groq Console

---

## üîë B∆∞·ªõc 2: L·∫•y API Key

### 2.1. V√†o API Keys Dashboard

Sau khi login:
1. Click menu **"API Keys"** b√™n tr√°i
2. Ho·∫∑c truy c·∫≠p: `https://console.groq.com/keys`

### 2.2. T·∫°o API Key m·ªõi

1. Click button **"Create API Key"**
2. ƒê·∫∑t t√™n cho key (v√≠ d·ª•: "Landing Hub Development")
3. Click **"Create"**

### 2.3. Copy API Key

‚ö†Ô∏è **QUAN TR·ªåNG**: API key ch·ªâ hi·ªán **1 l·∫ßn duy nh·∫•t**!

```
gsk_1234567890abcdefghijklmnopqrstuvwxyz...
```

- Click icon **Copy** ho·∫∑c Ctrl+C
- L∆∞u v√†o n∆°i an to√†n (password manager)
- **KH√îNG share** API key v·ªõi ai!

---

## ‚öôÔ∏è B∆∞·ªõc 3: C·∫•u h√¨nh Backend

### 3.1. T·∫°o/Edit file `.env`

```bash
cd /home/user/landing-hub/backend
```

N·∫øu ch∆∞a c√≥ file `.env`, t·∫°o m·ªõi:
```bash
touch .env
```

### 3.2. Th√™m Groq configuration

M·ªü `.env` v√† th√™m:

```bash
# ==========================================
# GROQ AI CONFIGURATION (FREE & FAST)
# ==========================================

# Groq API Key (from console.groq.com)
GROQ_API_KEY=gsk_YOUR_API_KEY_HERE

# Model selection
# Options: llama-3.3-70b-versatile, mixtral-8x7b-32768, llama-3.1-70b-versatile
GROQ_MODEL=llama-3.3-70b-versatile

# Set Groq as primary provider
AI_PROVIDER=groq

# Optional: Fallback providers (if Groq fails)
OPENAI_API_KEY=sk_optional_openai_key
GEMINI_API_KEY=optional_gemini_key
```

### 3.3. Replace placeholder

Thay `gsk_YOUR_API_KEY_HERE` b·∫±ng API key th·ª±c:

```bash
GROQ_API_KEY=gsk_1234567890abcdefghijklmnopqrstuvwxyz...
```

---

## üöÄ B∆∞·ªõc 4: Ch·ªçn Model

Groq h·ªó tr·ª£ nhi·ªÅu models. Ch·ªçn 1 trong c√°c options:

### Option 1: Llama 3.3 70B Versatile (RECOMMENDED)

```bash
GROQ_MODEL=llama-3.3-70b-versatile
```

- ‚úÖ **Best balance**: Quality + Speed
- ‚úÖ M·ªõi nh·∫•t (Dec 2024)
- ‚úÖ X·ª≠ l√Ω ti·∫øng Vi·ªát t·ªët
- ‚úÖ Context window: 8,192 tokens
- **Use case**: Production chatbot

### Option 2: Mixtral 8x7B

```bash
GROQ_MODEL=mixtral-8x7b-32768
```

- ‚úÖ **Fastest** responses
- ‚úÖ Context window l·ªõn: 32,768 tokens
- ‚ö†Ô∏è Quality h∆°i k√©m Llama 3.3
- **Use case**: High-traffic, speed critical

### Option 3: Llama 3.1 70B

```bash
GROQ_MODEL=llama-3.1-70b-versatile
```

- ‚úÖ Stable, proven quality
- ‚úÖ Good Vietnamese support
- ‚ö†Ô∏è Slightly slower than 3.3
- **Use case**: Conservative choice

### So s√°nh Models:

| Model | Speed | Quality | Context | Vietnamese |
|-------|-------|---------|---------|------------|
| **Llama 3.3 70B** | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 8K | Excellent |
| **Mixtral 8x7B** | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 32K | Very Good |
| **Llama 3.1 70B** | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 8K | Excellent |

---

## üß™ B∆∞·ªõc 5: Test Configuration

### 5.1. Start Backend

```bash
cd /home/user/landing-hub/backend
npm run dev
```

Expected output:
```
Server running on port 5000
MongoDB connected
ü§ñ Using AI provider: Groq (llama-3.3-70b-versatile)
```

### 5.2. Test Provider Status

```bash
curl http://localhost:5000/api/chat/provider-status
```

Expected response:
```json
{
  "success": true,
  "providers": [
    {
      "provider": "groq",
      "name": "Groq",
      "enabled": true,
      "model": "llama-3.3-70b-versatile",
      "active": true
    }
  ]
}
```

### 5.3. Test Chat

Start frontend:
```bash
cd /home/user/landing-hub/apps/web
npm start
```

M·ªü chat v√† th·ª≠:
```
"Template n√†o ƒëang b√°n ch·∫°y?"
```

Check backend logs - ph·∫£i th·∫•y:
```
ü§ñ Using AI provider: Groq (llama-3.3-70b-versatile)
```

---

## üîß B∆∞·ªõc 6: Advanced Configuration

### 6.1. Multiple Providers Setup

ƒê·ªÉ c√≥ **fallback** khi Groq down:

```bash
# Primary: Groq (free, fast)
GROQ_API_KEY=gsk_...
GROQ_MODEL=llama-3.3-70b-versatile
AI_PROVIDER=groq

# Fallback 1: Gemini (free)
GEMINI_API_KEY=AIzaSy...
GEMINI_MODEL=gemini-1.5-flash

# Fallback 2: OpenAI (paid, best quality)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
```

System s·∫Ω t·ª± ƒë·ªông fallback n·∫øu Groq l·ªói!

### 6.2. Auto Provider Selection

ƒê·ªÉ system t·ª± ch·ªçn provider t·ªët nh·∫•t:

```bash
AI_PROVIDER=auto
```

Th·ª© t·ª± ∆∞u ti√™n: **Groq ‚Üí Gemini ‚Üí OpenAI ‚Üí Ollama**

### 6.3. Environment-specific Setup

**Development:**
```bash
AI_PROVIDER=groq
GROQ_MODEL=mixtral-8x7b-32768  # Fastest for dev
```

**Production:**
```bash
AI_PROVIDER=groq
GROQ_MODEL=llama-3.3-70b-versatile  # Best balance
```

---

## üìä B∆∞·ªõc 7: Monitoring & Benchmarking

### 7.1. Check Logs

Backend logs s·∫Ω show:
```
ü§ñ Using AI provider: Groq (llama-3.3-70b-versatile)
‚úÖ Response time: 1247ms
```

### 7.2. Run Benchmark

Test Groq vs c√°c providers kh√°c:

```bash
# Create admin token first
# Then run benchmark API

curl -X POST http://localhost:5000/api/research/benchmark/run \
  -H "Authorization: Bearer YOUR_ADMIN_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "providers": ["groq", "openai", "gemini"],
    "category": "all"
  }'
```

### 7.3. View Stats

```bash
curl http://localhost:5000/api/research/benchmark/stats \
  -H "Authorization: Bearer YOUR_ADMIN_TOKEN"
```

Expected results:
```json
{
  "avgScores": {
    "groq": "8.45"
  },
  "avgLatency": {
    "groq": 1250
  },
  "totalCost": {
    "groq": 0
  },
  "winRate": {
    "groq": "38.0%"
  }
}
```

---

## ‚ö° Optimization Tips

### 1. Adjust Temperature

Trong `aiResponseService.js`:

```javascript
const aiResponse = await multiAIProvider.chatCompletion([...], {
  temperature: 0.5,  // 0.0 = deterministic, 1.0 = creative
  maxTokens: 1000
});
```

- **0.3-0.5**: Factual answers (recommend cho chatbot)
- **0.7-0.9**: Creative responses
- **0.0**: Deterministic (same question ‚Üí same answer)

### 2. Reduce Tokens

Groq free tier: **30 requests/minute**

ƒê·ªÉ t·ªëi ∆∞u:
```javascript
maxTokens: 500  // Thay v√¨ 1000 n·∫øu mu·ªën ng·∫Øn g·ªçn
```

### 3. Context Optimization

Ch·ªâ inject data c·∫ßn thi·∫øt:

```javascript
// N·∫øu user kh√¥ng h·ªèi v·ªÅ analytics, skip fetch
if (!lowerMessage.includes('views') && !lowerMessage.includes('conversion')) {
  // Skip getUserPageAnalytics()
}
```

---

## üêõ Troubleshooting

### Issue 1: "No AI provider configured"

**L√Ω do**: `.env` ch∆∞a c√≥ GROQ_API_KEY

**Fix**:
```bash
# Check .env file exists
ls -la backend/.env

# Add GROQ_API_KEY
echo "GROQ_API_KEY=gsk_your_key" >> backend/.env
```

### Issue 2: "Groq API error: 401 Unauthorized"

**L√Ω do**: API key sai ho·∫∑c expired

**Fix**:
1. V√†o https://console.groq.com/keys
2. X√≥a key c≈©
3. T·∫°o key m·ªõi
4. Update `.env`
5. Restart backend

### Issue 3: "Rate limit exceeded"

**L√Ω do**: > 30 requests/minute

**Fix Option 1** - Fallback:
```bash
# Add Gemini fallback
GEMINI_API_KEY=AIzaSy...
```

**Fix Option 2** - Throttle:
```javascript
// Add delay between requests
await new Promise(resolve => setTimeout(resolve, 2000));
```

### Issue 4: Slow responses

**L√Ω do**: Model qu√° n·∫∑ng ho·∫∑c prompt qu√° d√†i

**Fix**:
```bash
# Switch to faster model
GROQ_MODEL=mixtral-8x7b-32768
```

### Issue 5: Vietnamese quality k√©m

**L√Ω do**: Model kh√¥ng t·ªët cho ti·∫øng Vi·ªát

**Fix**:
```bash
# Use Llama 3.3 (best for Vietnamese)
GROQ_MODEL=llama-3.3-70b-versatile
```

---

## üìà Monitoring Dashboard

### Check Active Provider

Frontend c√≥ th·ªÉ check:
```javascript
const response = await axios.get('/api/chat/provider-status');
console.log('Active:', response.data.providers.find(p => p.active));
```

### Response Metadata

M·ªói AI response c√≥:
```javascript
{
  response: "...",
  aiProvider: "Groq",
  aiModel: "llama-3.3-70b-versatile",
  contextUsed: { ... }
}
```

Display trong chat:
```jsx
<Chip label={`Powered by ${aiProvider}`} size="small" />
```

---

## üéì Research Usage

### Benchmark Groq

```javascript
// Run comprehensive test
const results = await runBenchmark(
  ['groq'],
  'all',  // All categories
  userId
);

// Analyze
const stats = await getBenchmarkStats({
  'responses.provider': 'groq'
});

console.log('Groq avg score:', stats.avgScores.groq);
console.log('Groq avg latency:', stats.avgLatency.groq);
console.log('Groq win rate:', stats.winRate.groq);
```

### Compare with OpenAI

```javascript
const comparison = await compareProviders('groq', 'openai', 'marketplace');

console.log('Winner:',
  comparison.groq.avgScore > comparison.openai.avgScore ?
  'Groq' : 'OpenAI'
);
```

---

## üí° Pro Tips

### 1. Use Groq for Development

```bash
# .env.development
AI_PROVIDER=groq
GROQ_MODEL=mixtral-8x7b-32768  # Super fast for testing
```

### 2. Mix Providers in Production

```bash
# .env.production
AI_PROVIDER=groq              # Primary (free + fast)
OPENAI_API_KEY=sk_...         # Fallback (quality)
```

### 3. A/B Testing

```javascript
// Random provider selection for testing
const provider = Math.random() > 0.5 ? 'groq' : 'openai';
process.env.AI_PROVIDER = provider;
```

### 4. Cost Tracking

```javascript
// Log costs in production
console.log(`Cost: $${estimatedCost} | Provider: ${provider}`);
// Groq = $0.00 always!
```

---

## üìö Resources

### Official Docs
- Groq Console: https://console.groq.com
- API Docs: https://console.groq.com/docs
- Models: https://console.groq.com/docs/models

### Community
- Discord: https://discord.gg/groq
- Twitter: @GroqInc
- GitHub: https://github.com/groq

### Support
- Email: support@groq.com
- Docs: https://console.groq.com/docs/quickstart

---

## ‚úÖ Checklist Setup

- [ ] ƒêƒÉng k√Ω Groq account
- [ ] L·∫•y API key
- [ ] Th√™m v√†o `.env`: `GROQ_API_KEY`
- [ ] Set `AI_PROVIDER=groq`
- [ ] Ch·ªçn model: `GROQ_MODEL=llama-3.3-70b-versatile`
- [ ] Restart backend
- [ ] Test `/api/chat/provider-status`
- [ ] Test chat frontend
- [ ] Check logs: "Using AI provider: Groq"
- [ ] (Optional) Setup fallback providers
- [ ] (Optional) Run benchmark

---

## üéâ Ho√†n th√†nh!

B·∫°n ƒë√£ setup th√†nh c√¥ng Groq cho Landing Hub chatbot!

**K·∫øt qu·∫£**:
- ‚úÖ Chatbot mi·ªÖn ph√≠ 100%
- ‚úÖ Response time < 1.5s
- ‚úÖ Ch·∫•t l∆∞·ª£ng t·ªët (8.5/10)
- ‚úÖ Ti·∫øng Vi·ªát xu·∫•t s·∫Øc
- ‚úÖ Rate limit 30 req/min (ƒë·ªß x√†i)

**Next steps**:
1. Test v·ªõi real users
2. Run benchmarks
3. Monitor performance
4. Optimize prompts
5. Write research paper! üìù

Happy coding! üöÄ
